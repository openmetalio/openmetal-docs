"use strict";(self.webpackChunkopenmetal_docs=self.webpackChunkopenmetal_docs||[]).push([[6911],{3905:(e,t,n)=>{n.d(t,{Zo:()=>u,kt:()=>d});var a=n(67294);function i(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function r(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function o(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?r(Object(n),!0).forEach((function(t){i(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):r(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,a,i=function(e,t){if(null==e)return{};var n,a,i={},r=Object.keys(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||(i[n]=e[n]);return i}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(i[n]=e[n])}return i}var s=a.createContext({}),p=function(e){var t=a.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):o(o({},t),e)),n},u=function(e){var t=p(e.components);return a.createElement(s.Provider,{value:t},e.children)},c="mdxType",m={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},g=a.forwardRef((function(e,t){var n=e.components,i=e.mdxType,r=e.originalType,s=e.parentName,u=l(e,["components","mdxType","originalType","parentName"]),c=p(n),g=i,d=c["".concat(s,".").concat(g)]||c[g]||m[g]||r;return n?a.createElement(d,o(o({ref:t},u),{},{components:n})):a.createElement(d,o({ref:t},u))}));function d(e,t){var n=arguments,i=t&&t.mdxType;if("string"==typeof e||i){var r=n.length,o=new Array(r);o[0]=g;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l[c]="string"==typeof e?e:i,o[1]=l;for(var p=2;p<r;p++)o[p]=n[p];return a.createElement.apply(null,o)}return a.createElement.apply(null,n)}g.displayName="MDXCreateElement"},95167:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>s,contentTitle:()=>o,default:()=>c,frontMatter:()=>r,metadata:()=>l,toc:()=>p});var a=n(87462),i=(n(67294),n(3905));const r={slug:"/private-ai/engineering-notes/automate-mig-management",description:"Best practices for managing MIG device lifecycles, including automation tools and ensuring consistent GPU availability after reboot.",sidebar_position:7},o="Managing MIG Devices and Automating Lifecycle Operations",l={unversionedId:"private-ai/engineering-notes/automate-mig-management",id:"private-ai/engineering-notes/automate-mig-management",title:"Managing MIG Devices and Automating Lifecycle Operations",description:"Best practices for managing MIG device lifecycles, including automation tools and ensuring consistent GPU availability after reboot.",source:"@site/docs/private-ai/engineering-notes/automate-mig-management.md",sourceDirName:"private-ai/engineering-notes",slug:"/private-ai/engineering-notes/automate-mig-management",permalink:"/docs/manuals/private-ai/engineering-notes/automate-mig-management",draft:!1,editUrl:"https://github.com/openmetalio/openmetal-docs/blob/main/docs/private-ai/engineering-notes/automate-mig-management.md",tags:[],version:"current",sidebarPosition:7,frontMatter:{slug:"/private-ai/engineering-notes/automate-mig-management",description:"Best practices for managing MIG device lifecycles, including automation tools and ensuring consistent GPU availability after reboot.",sidebar_position:7},sidebar:"tutorialSidebar",previous:{title:"Monitoring, Scheduling, and Performance Management of Virtual GPUs",permalink:"/docs/manuals/private-ai/engineering-notes/monitoring-scheduling-vgpu"},next:{title:"Engineering Notes: Deploying A100 GPUs with MIG in OpenStack",permalink:"/docs/manuals/private-ai/engineering-notes/"}},s={},p=[{value:"Best Practices for MIG Instance Management",id:"best-practices-for-mig-instance-management",level:2},{value:"Automating MIG Creation with <code>nvidia-smi</code>",id:"automating-mig-creation-with-nvidia-smi",level:2},{value:"Automating with MIG Parted",id:"automating-with-mig-parted",level:2},{value:"Cleaning Up MIG Instances",id:"cleaning-up-mig-instances",level:2},{value:"Role in Private Cloud Operations",id:"role-in-private-cloud-operations",level:2},{value:"Summary",id:"summary",level:2}],u={toc:p};function c(e){let{components:t,...n}=e;return(0,i.kt)("wrapper",(0,a.Z)({},u,n,{components:t,mdxType:"MDXLayout"}),(0,i.kt)("h1",{id:"managing-mig-devices-and-automating-lifecycle-operations"},"Managing MIG Devices and Automating Lifecycle Operations"),(0,i.kt)("p",null,"Multi-Instance GPU (MIG) enables partitioning of a single NVIDIA A100 into\nisolated compute slices, but these configurations are ",(0,i.kt)("strong",{parentName:"p"},"not persistent")," by default.\nThis article outlines best practices for managing MIG devices in production\nenvironments and describes automation techniques to ensure consistent GPU\navailability after system events or reboots."),(0,i.kt)("p",null,"MIG State Is Not Persistent\nWhile enabling MIG mode is persistent across reboots on ",(0,i.kt)("strong",{parentName:"p"},"Ampere GPUs"),", the\n",(0,i.kt)("strong",{parentName:"p"},"specific GPU and compute instances")," created within MIG mode are ",(0,i.kt)("strong",{parentName:"p"},"ephemeral"),".\nIf a server restarts, all configured MIG partitions are lost unless re-created\nthrough automation."),(0,i.kt)("p",null,"To check MIG mode status:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"nvidia-smi -i 0 --query-gpu=mig.mode.current --format=csv\n")),(0,i.kt)("p",null,"To confirm instance existence:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"nvidia-smi mig -lgi\n")),(0,i.kt)("p",null,"If this list is empty after a reboot, MIG partitions must be re-created."),(0,i.kt)("hr",null),(0,i.kt)("h2",{id:"best-practices-for-mig-instance-management"},"Best Practices for MIG Instance Management"),(0,i.kt)("p",null,"Step 1. ",(0,i.kt)("strong",{parentName:"p"},"Use Predictable Profiles")),(0,i.kt)("p",null,"  Stick to known-good profiles such as:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},(0,i.kt)("inlineCode",{parentName:"p"},"1g.5gb")," for small workloads")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},(0,i.kt)("inlineCode",{parentName:"p"},"3g.20gb")," for balanced performance")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},(0,i.kt)("inlineCode",{parentName:"p"},"7g.40gb")," for full-GPU workloads"))),(0,i.kt)("p",null,"Avoid frequent reconfiguration, which can lead to resource fragmentation and\nscheduling failures."),(0,i.kt)("p",null,"Step 2. ",(0,i.kt)("strong",{parentName:"p"},"Predefine Instance Geometry")),(0,i.kt)("p",null,"  For consistency, document your MIG layout per node. Example layout for one A100:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"3x ",(0,i.kt)("inlineCode",{parentName:"li"},"1g.5gb")),(0,i.kt)("li",{parentName:"ul"},"1x ",(0,i.kt)("inlineCode",{parentName:"li"},"4g.20gb"))),(0,i.kt)("p",null,"Or:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"2x ",(0,i.kt)("inlineCode",{parentName:"li"},"3g.20gb")),(0,i.kt)("li",{parentName:"ul"},"1x ",(0,i.kt)("inlineCode",{parentName:"li"},"1g.5gb"))),(0,i.kt)("p",null,"This helps ensure compatibility with OpenStack traits and avoids flavor mismatches."),(0,i.kt)("p",null,"Step 3. ",(0,i.kt)("strong",{parentName:"p"},"Enable MIG Mode via Automation")),(0,i.kt)("p",null,"  If not already enabled, you can activate MIG mode during system provisioning:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"nvidia-smi -i 0 -mig 1\n")),(0,i.kt)("p",null,"This command can be included in a cloud-init script or post-boot automation."),(0,i.kt)("hr",null),(0,i.kt)("h2",{id:"automating-mig-creation-with-nvidia-smi"},"Automating MIG Creation with ",(0,i.kt)("inlineCode",{parentName:"h2"},"nvidia-smi")),(0,i.kt)("p",null,"To recreate MIG geometry after reboot, run:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"sudo nvidia-smi mig -cgi 19,19,19 -C\n")),(0,i.kt)("p",null,"This creates three instances of profile ID 19 (",(0,i.kt)("inlineCode",{parentName:"p"},"1g.5gb"),"). You can use other profile\nIDs as needed, and combine them in one call."),(0,i.kt)("p",null,"For production environments, embed this logic in a startup script or systemd unit."),(0,i.kt)("hr",null),(0,i.kt)("h2",{id:"automating-with-mig-parted"},"Automating with MIG Parted"),(0,i.kt)("p",null,"MIG Parted is an NVIDIA-provided tool that simplifies configuration and layout\nof MIG profiles. It allows:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Declarative geometry files"),(0,i.kt)("li",{parentName:"ul"},"Repeatable MIG creation"),(0,i.kt)("li",{parentName:"ul"},"Easy rollback or reconfiguration")),(0,i.kt)("p",null,"Example systemd unit:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"[Unit]\nDescription=Configure MIG on boot\nAfter=multi-user.target\n\n\n[Service]\nExecStart=/usr/bin/mig-parted apply /etc/mig-layout.yaml\nType=oneshot\nRemainAfterExit=true\n\n[Install]\nWantedBy=multi-user.target\n")),(0,i.kt)("p",null,"This ensures that every time a node boots, the expected MIG layout is applied\nbefore VMs are scheduled."),(0,i.kt)("hr",null),(0,i.kt)("h2",{id:"cleaning-up-mig-instances"},"Cleaning Up MIG Instances"),(0,i.kt)("p",null,"Before modifying geometry, destroy compute and GPU instances:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"nvidia-smi mig -dci\nnvidia-smi mig -dgi\n")),(0,i.kt)("p",null,"Failure to clean up instances can result in placement errors or resource\nallocation conflicts."),(0,i.kt)("hr",null),(0,i.kt)("h2",{id:"role-in-private-cloud-operations"},"Role in Private Cloud Operations"),(0,i.kt)("p",null,"In OpenMetal's infrastructure, automation of MIG ensures that:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},"GPU instances are restored predictably")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},"Virtual machines can rely on scheduled GPU traits")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},"Workload performance remains consistent after upgrades or failures"))),(0,i.kt)("p",null,"This is especially important for high-availability and multi-tenant\nenvironments where GPU-backed workloads are tightly integrated into production workflows."),(0,i.kt)("hr",null),(0,i.kt)("h2",{id:"summary"},"Summary"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"MIG partitions must be recreated after host reboots"),(0,i.kt)("li",{parentName:"ul"},"Use ",(0,i.kt)("inlineCode",{parentName:"li"},"nvidia-smi")," or ",(0,i.kt)("inlineCode",{parentName:"li"},"mig-parted")," for repeatable layouts"),(0,i.kt)("li",{parentName:"ul"},"Automate MIG configuration with systemd or init scripts"),(0,i.kt)("li",{parentName:"ul"},"Match MIG profiles to OpenStack traits to ensure correct VM scheduling")),(0,i.kt)("hr",null),(0,i.kt)("p",null,"This completes the 7-part series on deploying and managing NVIDIA A100 GPUs using\nMIG in a private cloud environment with OpenStack."))}c.isMDXComponent=!0}}]);